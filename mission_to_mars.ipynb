{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create executable path\n",
    "executable_path = {\"executable_path\": 'chromedriver.exe'}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News about Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to site\n",
    "url_news = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url_news)\n",
    "\n",
    "#Create delay for load time\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the News Title\n",
    "news = soup.find('div', class_= 'content_title')\n",
    "news_title = news.find('a').text.strip()\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_p = soup.find('div', class_= 'rollover_description_inner').text.strip()\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars space image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_image = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit image website\n",
    "browser.visit(url_image)\n",
    "\n",
    "#Create a Delay for load time\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get featured image\n",
    "relative_image_path = soup.find('footer').find('a').attrs['data-fancybox-href']\n",
    "feature_img = \"https://www.jpl.nasa.gov\" + relative_image_path\n",
    "feature_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars facts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for space facts table\n",
    "url_table = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit image website\n",
    "browser.visit(url_table)\n",
    "time.sleep(5)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tables\n",
    "facts_tables = pd.read_html(url_table)\n",
    "facts_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find first table and label columns\n",
    "df = facts_tables[0]\n",
    "df.columns = ['Description', 'Value']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push table to html \n",
    "mars_facts = df.to_html(index=False)\n",
    "print(mars_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars weather tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_twitter = \"https://twitter.com/marswxreport?lang=en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit image website\n",
    "browser.visit(url_twitter)\n",
    "\n",
    "#Create a Delay for load time\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tweet = soup.find('div',class_=\"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x \\\n",
    "r-bcqeeo r-bnwqim r-qvutc0\").find('span').text.replace('\\n', ' ')\n",
    "\n",
    "# weather_tweet = soup.find('div',class_='js-tweet-text-container').find('p').text.replace('\\n', ' ')\n",
    "weather_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     flag = False\n",
    "#     while flag == False:\n",
    "#         try:\n",
    "#             url_twitter = \"https://twitter.com/marswxreport?lang=en\"\n",
    "#             browser.visit(url_twitter)\n",
    "#             time.sleep(5)\n",
    "#             html = browser.html\n",
    "#             soup = bs(html,'html.parser')\n",
    "#             weather_tweet = soup.find('div',class_=\"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x \\\n",
    "#             r-bcqeeo r-bnwqim r-qvutc0\").find('span').text.replace('\\n', ' ')\n",
    "#             flag = True\n",
    "            \n",
    "#             if(flag == False):\n",
    "#                 try:\n",
    "            \n",
    "#                     url_twitter = \"https://twitter.com/marswxreport?lang=en\"\n",
    "#                     browser.visit(url_twitter)\n",
    "#                     time.sleep(5)\n",
    "#                     html = browser.html\n",
    "#                     soup = bs(html,'html.parser')\n",
    "#                     weather_tweet = soup.find('p',class_='tweet-text').text.replace('\\n', ' ')\n",
    "#                     flag = True\n",
    "#                 except:\n",
    "#                     print('Wrong twitter version trying again')\n",
    "#                     flag = False\n",
    "    flag = False\n",
    "    while flag == False:\n",
    "        try:\n",
    "            url_twitter = \"https://twitter.com/marswxreport?lang=en\"\n",
    "            browser.visit(url_twitter)\n",
    "            time.sleep(5)\n",
    "            html = browser.html\n",
    "            soup = bs(html,'html.parser')\n",
    "            weather_tweet = soup.find('div',class_=\"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0\").find('span').text.replace('\\n', ' ')\n",
    "            flag = True\n",
    "        except:\n",
    "            print('Wrong twitter version trying again')\n",
    "            flag = False\n",
    "            weather_tweet = soup.find('p',class_='tweet-text').text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_hems = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_hems)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variable for list of dictionaries.\n",
    "hem_img_title = []\n",
    "\n",
    "# Variable for attributes on initial page\n",
    "hemispheres = soup.find(\"div\", class_=\"result-list\").find_all(\"div\", class_=\"item\")\n",
    "\n",
    "# Loop through attributes to find each title and image\n",
    "for hemisphere in hemispheres:\n",
    "    title = hemisphere.find(\"h3\").text\n",
    "# Drop \"Enhanced\" from each scraped title\n",
    "    title = title.replace(\"Enhanced\", \"\")\n",
    "# Get link for full image page\n",
    "    partial_link = hemisphere.find(\"a\")[\"href\"]\n",
    "    img_link = \"https://astrogeology.usgs.gov/\" + partial_link    \n",
    "# Visit page with full image and scrape\n",
    "    browser.visit(img_link)\n",
    "    soup = bs(browser.html, \"html.parser\")\n",
    "    img_url = soup.find(\"div\", class_=\"downloads\").find(\"a\")[\"href\"]\n",
    "# Append dictionaries to list\n",
    "    hem_img_title.append({\"title\": title, \"img_url\": img_url})\n",
    "    \n",
    "print(hem_img_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store data in dictionary\n",
    "\n",
    "mars_info = {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_p\": news_p,\n",
    "        \"feature_img\": feature_img,\n",
    "        \"mars_facts\": mars_facts,\n",
    "        \"weather_tweet\": weather_tweet,\n",
    "        \"hemispheres\": hem_img_title\n",
    "    }\n",
    "    \n",
    "print(mars_info)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:testenv] *",
   "language": "python",
   "name": "conda-env-testenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
